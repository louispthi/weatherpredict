{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI01g1bPRkj6"
   },
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",

   "metadata": {
    "id": "DidIiT5zRkkG"
   },
   "source": [
    "We use Keras to create a Neural Network Model. RNNs, and especially LSTMs, seem to be particularly good for time-series predictions, so this is our strategy. Our goal is to provide 36 hours forecast of the temperature using 4 days of temperature data. We run the machine learning model on the Google Colab GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-6WbB7xRkkH"
   },
   "source": [
    "### Importing libraries and getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzsbt_XeSRMb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh3PsRHGSbpU"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/My Drive\""

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AJfTflDRkkH"
   },
   "source": [
    "We upload the libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1609091880412,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "ZRxLOeJgRkkI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1609116090729,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "GhKFg_FqRkkJ",
    "outputId": "204824fb-fef0-4cc8-8ea4-8f697bb52c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape = (364512, 13)\n",
      "Index(['temp', 'feels_like', 'pressure', 'humidity', 'wind_speed', 'wind_deg',\n",
      "       'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds_all', 'weather_id',\n",
      "       'weather_main'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_nn = pd.read_csv('/content/drive/My Drive/weatherpredict/weather_data_initial_clean.csv')\n",
    "df_nn['dt_iso'] = pd.to_datetime(df_nn['dt_iso'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_nn = df_nn.set_index('dt_iso')\n",
    "print('Data Shape = {}'.format(df_nn.shape))\n",
    "print(df_nn.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1U1GZN6aRkkK"
   },
   "source": [
    "We only keep the temperature column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1609116091928,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "sLk1ISg8RkkL"
   },
   "outputs": [],
   "source": [
    "df_nn = df_nn['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1609116093463,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "AFwW4DReRkkL",
    "outputId": "d8b1ecf7-c854-4cde-8cad-f1b455cc7192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364512"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8faeebJDRkkM"
   },
   "source": [
    "### Preparing training and test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzzBik3vRkkM"
   },
   "source": [
    "We first split the data into a training set and a test set. As we have time-series data, it is important to not shuffle those sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1609116095932,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "4pImQHF0RkkN"
   },
   "outputs": [],
   "source": [
    "# Splitting into training and test data, in a 80-20 split\n",
    "split_point = int(len(df_nn)*(80/100))\n",
    "nn_train = df_nn[:split_point]\n",
    "nn_test = df_nn[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1609115968377,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "IGWdy0Q1RkkN",
    "outputId": "f63aa9ff-c509-4ea3-b9ac-3804fa5dc9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of nn_train: 291609\n",
      "Length of nn_test: 72903\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of nn_train:\", len(nn_train))\n",
    "print(\"Length of nn_test:\", len(nn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fyTpvK2RkkO"
   },
   "source": [
    "Next we use MinMaxScaler to normalise the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1609116099150,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "AnIv3A4DRkkO",
    "outputId": "6b8fa6c0-f888-4c9e-9103-b875fb92e7ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of nn_train:  (291609, 1)\n",
      "Shape of nn_test:  (72903, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transforming data into numpy array \n",
    "\n",
    "nn_train = nn_train.to_numpy().reshape(-1,1)\n",
    "nn_test = nn_test.to_numpy().reshape(-1,1)\n",
    "\n",
    "print(\"Shape of nn_train: \", nn_train.shape)\n",
    "print(\"Shape of nn_test: \", nn_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1609116102114,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "zoRViGalRkkO"
   },
   "outputs": [],
   "source": [
    "# Normalising using MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "nn_train_norm = min_max_scaler.fit_transform(nn_train)\n",
    "nn_test_norm = min_max_scaler.transform(nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1609116104524,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "dHKE5Ix0RkkP",
    "outputId": "acc79692-0163-42ee-d12c-717147195545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of nn_train_norm:  (291609, 1)\n",
      "Shape of nn_test_norm:  (72903, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of nn_train_norm: \", nn_train_norm.shape)\n",
    "print(\"Shape of nn_test_norm: \", nn_test_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1488,
     "status": "ok",
     "timestamp": 1609116107747,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "ShLNwQH_RkkP",
    "outputId": "59b1f7c6-cae3-4db0-8d97-64f3c8588d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "x_train:  (291478, 96, 1)\n",
      "y_train:  (291478, 36)\n",
      "x_test:  (72772, 96, 1)\n",
      "y_test:  (72772, 36)\n"
     ]
    }
   ],
   "source": [
    "# Creating train and test data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Setting 'n_future' days to predict using 'n_past'days. \n",
    "n_future = 1.5\n",
    "n_past = 4\n",
    "\n",
    "# Getting number of hours \n",
    "n_future = int(n_future * 24)\n",
    "n_past = int(n_past * 24) \n",
    "\n",
    "for i in range(0,len(nn_train_norm)-n_past-n_future+1):\n",
    "    x_train.append(nn_train_norm[i : i + n_past , 0])     \n",
    "    y_train.append(nn_train_norm[i + n_past : i + n_past + n_future , 0 ])\n",
    "for i in range(0,len(nn_test_norm)-n_past-n_future+1):\n",
    "    x_test.append(nn_test_norm[i : i + n_past , 0])  \n",
    "    y_test.append(nn_test_norm[i + n_past : i + n_past + n_future , 0 ])\n",
    "\n",
    "x_train , y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], 1) )\n",
    "x_test = np.reshape(x_test, (x_test.shape[0] , x_test.shape[1], 1) )\n",
    "\n",
    "print('Training data:')\n",
    "print('x_train: ', x_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('x_test: ', x_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2f0Co8mRkkR"
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zC6wbwGvRkkR"
   },
   "source": [
    "We built the model using LSTM. We use Google Colab to perform the computations using a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16383684,
     "status": "ok",
     "timestamp": 1609114219242,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "ZD-8T64nRkkR",
    "outputId": "e15769d7-a8f4-4b89-8546-0165aa2cd392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "570/570 [==============================] - 823s 1s/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1340\n",
      "Epoch 2/20\n",
      "570/570 [==============================] - 825s 1s/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0687\n",
      "Epoch 3/20\n",
      "570/570 [==============================] - 819s 1s/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0578\n",
      "Epoch 4/20\n",
      "570/570 [==============================] - 807s 1s/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0526\n",
      "Epoch 5/20\n",
      "570/570 [==============================] - 816s 1s/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0500\n",
      "Epoch 6/20\n",
      "570/570 [==============================] - 826s 1s/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0483\n",
      "Epoch 7/20\n",
      "570/570 [==============================] - 822s 1s/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0469\n",
      "Epoch 8/20\n",
      "570/570 [==============================] - 827s 1s/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0458\n",
      "Epoch 9/20\n",
      "570/570 [==============================] - 809s 1s/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450\n",
      "Epoch 10/20\n",
      "570/570 [==============================] - 822s 1s/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0445\n",
      "Epoch 11/20\n",
      "570/570 [==============================] - 837s 1s/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0438\n",
      "Epoch 12/20\n",
      "570/570 [==============================] - 829s 1s/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0435\n",
      "Epoch 13/20\n",
      "570/570 [==============================] - 815s 1s/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0432\n",
      "Epoch 14/20\n",
      "570/570 [==============================] - 802s 1s/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0429\n",
      "Epoch 15/20\n",
      "570/570 [==============================] - 816s 1s/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0427\n",
      "Epoch 16/20\n",
      "570/570 [==============================] - 822s 1s/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0425\n",
      "Epoch 17/20\n",
      "570/570 [==============================] - 825s 1s/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0423\n",
      "Epoch 18/20\n",
      "570/570 [==============================] - 807s 1s/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0422\n",
      "Epoch 19/20\n",
      "570/570 [==============================] - 810s 1s/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0420\n",
      "Epoch 20/20\n",
      "570/570 [==============================] - 824s 1s/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe97e4e6518>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = x_train.shape[1]\n",
    "\n",
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(Bidirectional(LSTM(units=units, return_sequences=True, input_shape = (x_train.shape[1],1) ) ))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units= units , return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units= units , return_sequences=True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units= units))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = n_future,activation='linear'))\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "regressor.fit(x_train, y_train, epochs=20,batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83a9gtPrv2h9"
   },
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model. We will test it and analyse results in the 'lstm_model_test' notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1609115672665,
     "user": {
      "displayName": "Louis-Philippe Thibault",
      "photoUrl": "",
      "userId": "09437908589592838732"
     },
     "user_tz": 300
    },
    "id": "Jjsx4avqv3iS"
   },
   "outputs": [],
   "source": [
    "regressor.save(\"/content/drive/My Drive/weatherpredict/lstm_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "weather_nn_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
